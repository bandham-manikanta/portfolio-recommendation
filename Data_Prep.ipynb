{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Link drive\n",
    "# prompt: link drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "os.chdir('/content/drive/MyDrive/project_598/Akhil_Project')\n",
    "print(os.getcwd())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ef65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fredapi\n",
    "! pip install pandas_ta\n",
    "! pip install fastparquet\n",
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import holidays\n",
    "import pandas_ta as ta\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58692ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Fred with your API key\n",
    "fred = Fred(api_key='your_fred_api_key')  # Replace with your actual API key securely\n",
    "\n",
    "# Define date range\n",
    "start_date = '2002-01-01'\n",
    "end_date = '2024-11-28'\n",
    "\n",
    "# Define the indicators and their series IDs\n",
    "indicators = {\n",
    "    'Effective Federal Funds Rate': 'FEDFUNDS',\n",
    "    '10-Year Treasury Rate': 'DGS10',\n",
    "    'Consumer Price Index': 'CPIAUCSL',\n",
    "    'Producer Price Index': 'PPIACO',\n",
    "    'Unemployment Rate': 'UNRATE',\n",
    "    'Nonfarm Payroll Employment': 'PAYEMS',\n",
    "    'Real GDP': 'GDPC1',\n",
    "    'Housing Starts': 'HOUST',\n",
    "    'Industrial Production Index': 'INDPRO',\n",
    "    'M2 Money Stock': 'M2SL',\n",
    "    'Crude Oil Prices': 'DCOILWTICO',\n",
    "    'Retail Sales': 'RSXFS',\n",
    "    'Total Business Inventories': 'BUSINV'\n",
    "}\n",
    "\n",
    "# Fetch the data with date range\n",
    "economic_data = pd.DataFrame()\n",
    "\n",
    "for name, series_id in indicators.items():\n",
    "    try:\n",
    "        data = fred.get_series(\n",
    "            series_id,\n",
    "            observation_start=start_date,\n",
    "            observation_end=end_date\n",
    "        )\n",
    "        if data is not None and not data.empty:\n",
    "            economic_data[name] = data\n",
    "            print(f\"Successfully fetched data for {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {name}: {e}\")\n",
    "\n",
    "# Convert index to datetime if not already\n",
    "economic_data.index = pd.to_datetime(economic_data.index)\n",
    "\n",
    "# Ensure the DataFrame is sorted by date\n",
    "economic_data.sort_index(inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "def fill_missing_values(df):\n",
    "    df_filled = df.copy()\n",
    "\n",
    "    # Ensure index is DatetimeIndex\n",
    "    if not isinstance(df_filled.index, pd.DatetimeIndex):\n",
    "        df_filled.index = pd.to_datetime(df_filled.index)\n",
    "    df_filled.sort_index(inplace=True)\n",
    "\n",
    "    # Create Month and Year columns once\n",
    "    df_filled['Month'] = df_filled.index.month\n",
    "    df_filled['Year'] = df_filled.index.year\n",
    "\n",
    "    # Process each column individually\n",
    "    for column in df.columns:\n",
    "        col_data = df_filled[['Year', 'Month', column]].copy()\n",
    "\n",
    "        # Calculate monthly means\n",
    "        monthly_means = col_data.groupby(['Year', 'Month'])[column].mean().rename('Monthly_Mean').reset_index()\n",
    "\n",
    "        # Merge monthly means back into col_data\n",
    "        col_data = col_data.merge(monthly_means, on=['Year', 'Month'], how='left')\n",
    "\n",
    "        # Fill missing values with Monthly Mean\n",
    "        null_mask = col_data[column].isnull()\n",
    "        col_data.loc[null_mask, column] = col_data.loc[null_mask, 'Monthly_Mean']\n",
    "\n",
    "        # Calculate yearly means\n",
    "        yearly_means = col_data.groupby('Year')[column].mean().rename('Yearly_Mean').reset_index()\n",
    "\n",
    "        # Merge yearly means into col_data\n",
    "        col_data = col_data.merge(yearly_means, on='Year', how='left')\n",
    "\n",
    "        # Fill remaining missing values with Yearly Mean\n",
    "        still_null_mask = col_data[column].isnull()\n",
    "        col_data.loc[still_null_mask, column] = col_data.loc[still_null_mask, 'Yearly_Mean']\n",
    "\n",
    "        # Update the filled values back into df_filled\n",
    "        df_filled.loc[:, column] = col_data[column].values\n",
    "\n",
    "    # Drop the auxiliary columns\n",
    "    df_filled.drop(['Month', 'Year'], axis=1, inplace=True)\n",
    "\n",
    "    return df_filled\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "economic_data_filled = fill_missing_values(economic_data)\n",
    "economic_data_filled.index = pd.to_datetime(economic_data_filled.index)\n",
    "economic_data_filled.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stock data\n",
    "stock_data = pd.read_parquet('sp500_50stocks_data.parquet')\n",
    "# Convert index to DatetimeIndex if not already\n",
    "stock_data.index = pd.to_datetime(stock_data.index)\n",
    "# Sort by date\n",
    "stock_data.sort_index(inplace=True)\n",
    "\n",
    "# Flatten MultiIndex columns in stock_data\n",
    "stock_data.columns = ['_'.join(col).strip() for col in stock_data.columns.values]\n",
    "\n",
    "# Merge economic data with stock data\n",
    "economic_data_filled.index.name = 'Date'\n",
    "stock_data.index.name = 'Date'\n",
    "\n",
    "# Create a daily date range based on stock data index\n",
    "daily_date_range = pd.date_range(\n",
    "    start=stock_data.index.min(),\n",
    "    end=stock_data.index.max(),\n",
    "    freq='D'  # Daily frequency\n",
    ")\n",
    "\n",
    "# Reindex economic data to daily frequency using forward fill\n",
    "economic_data_daily = economic_data_filled.reindex(daily_date_range, method='ffill')\n",
    "economic_data_daily.index.name = 'Date'\n",
    "\n",
    "# Merge the DataFrames using the date index\n",
    "combined_data = stock_data.join(economic_data_daily, how='left')\n",
    "combined_data.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Feature Engineering\n",
    "\n",
    "tickers = [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"GOOGL\", \"AMZN\", \"META\", \"AVGO\", \"LLY\", \"TSLA\",\n",
    "           \"WMT\", \"JPM\", \"V\", \"XOM\", \"UNH\", \"ORCL\", \"MA\", \"HD\", \"PG\", \"COST\", \"JNJ\",\n",
    "           \"NFLX\", \"ABBV\", \"BAC\", \"KO\", \"CRM\", \"CVX\", \"MRK\", \"TMUS\", \"AMD\", \"PEP\",\n",
    "           \"ACN\", \"LIN\", \"TMO\", \"MCD\", \"CSCO\", \"ADBE\", \"WFC\", \"IBM\", \"GE\", \"ABT\",\n",
    "           \"DHR\", \"AXP\", \"MS\", \"CAT\", \"NOW\", \"QCOM\", \"PM\", \"ISRG\", \"VZ\"]\n",
    "\n",
    "print(\"Initial number of columns:\", len(combined_data.columns))\n",
    "\n",
    "for ticker in tickers:\n",
    "    close_col = f'{ticker}_Close'\n",
    "\n",
    "    if close_col in combined_data.columns:\n",
    "        # Calculate technical indicators\n",
    "        combined_data[f'{ticker}_SMA_20'] = ta.sma(combined_data[close_col], length=20)\n",
    "        combined_data[f'{ticker}_RSI_14'] = ta.rsi(combined_data[close_col], length=14)\n",
    "        macd = ta.macd(combined_data[close_col], fast=12, slow=26)\n",
    "        macd_columns = [f'{ticker}_MACD', f'{ticker}_MACD_Hist', f'{ticker}_MACD_Signal']\n",
    "        macd.columns = macd_columns\n",
    "        combined_data = pd.concat([combined_data, macd], axis=1)\n",
    "        bbands = ta.bbands(combined_data[close_col], length=20)\n",
    "        bbands_columns = [f'{ticker}_BB_Lower', f'{ticker}_BB_Middle', f'{ticker}_BB_Upper', f'{ticker}_BB_Bandwidth', f'{ticker}_BB_Percentage']\n",
    "        bbands.columns = bbands_columns\n",
    "        combined_data = pd.concat([combined_data, bbands], axis=1)\n",
    "        combined_data[f'{ticker}_MOM_10'] = ta.mom(combined_data[close_col], length=10)\n",
    "    else:\n",
    "        print(f'Column {close_col} not found in combined_data.')\n",
    "\n",
    "print(\"Number of columns after adding technical indicators:\", len(combined_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features\n",
    "n_lags = 5\n",
    "lagged_features = {}\n",
    "\n",
    "# Create lag features for stock prices\n",
    "for ticker in tickers:\n",
    "    close_col = f'{ticker}_Close'\n",
    "\n",
    "    if close_col in combined_data.columns:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            lag_col_name = f'{ticker}_Close_Lag_{lag}'\n",
    "            lagged_features[lag_col_name] = combined_data[close_col].shift(lag)\n",
    "    else:\n",
    "        print(f'Column {close_col} not found in combined_data.')\n",
    "\n",
    "# Create lag features for economic indicators\n",
    "economic_indicators = economic_data_filled.columns.tolist()\n",
    "\n",
    "for indicator in economic_indicators:\n",
    "    if indicator in combined_data.columns:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            lag_col_name = f'{indicator}_Lag_{lag}'\n",
    "            lagged_features[lag_col_name] = combined_data[indicator].shift(lag)\n",
    "    else:\n",
    "        print(f'Indicator {indicator} not found in combined_data.')\n",
    "\n",
    "# Convert the lagged features dictionary to a DataFrame\n",
    "lagged_features_df = pd.DataFrame(lagged_features, index=combined_data.index)\n",
    "\n",
    "# Concatenate the lagged features DataFrame to the original DataFrame\n",
    "combined_data = pd.concat([combined_data, lagged_features_df], axis=1)\n",
    "combined_data = combined_data.copy()\n",
    "\n",
    "print(f\"Total number of columns after adding lag features: {len(combined_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Date-Based Features\n",
    "\n",
    "# Extract day of the week\n",
    "combined_data['Day_of_Week'] = combined_data.index.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# Extract month\n",
    "combined_data['Month'] = combined_data.index.month\n",
    "\n",
    "# Extract quarter\n",
    "combined_data['Quarter'] = combined_data.index.quarter\n",
    "\n",
    "# Identify US holidays\n",
    "us_holidays = holidays.US()\n",
    "combined_data['Is_Holiday'] = combined_data.index.isin(us_holidays).astype(int)\n",
    "\n",
    "# Identify month start and end\n",
    "combined_data['Is_Month_Start'] = combined_data.index.is_month_start.astype(int)\n",
    "combined_data['Is_Month_End'] = combined_data.index.is_month_end.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a47d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split combined data into individual company DataFrames\n",
    "all_dfs = {}  # Dictionary to store DataFrames\n",
    "\n",
    "for tick in tickers:\n",
    "    # Create a dynamic DataFrame name\n",
    "    df_name = \"df_\" + tick\n",
    "\n",
    "    # Filter the combined_data DataFrame for columns matching the ticker\n",
    "    company_df = combined_data.filter(like=tick, axis=1)\n",
    "\n",
    "    # Add date-based features and economic indicators\n",
    "    company_df = pd.concat([company_df, combined_data[['Day_of_Week', 'Month', 'Quarter', 'Is_Holiday', 'Is_Month_Start', 'Is_Month_End']], combined_data[economic_indicators]], axis=1)\n",
    "\n",
    "    # Add target variables\n",
    "    for i in range(1, 6):  # Forwarded columns for 1 to 5 steps\n",
    "        company_df[f'{tick}_target_{i}'] = company_df[f'{tick}_Close'].shift(-i)\n",
    "\n",
    "    # Drop missing values\n",
    "    company_df.dropna(inplace=True)\n",
    "\n",
    "    # Store the DataFrame in the dictionary\n",
    "    all_dfs[df_name] = company_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934016c3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Adjust DataFrames for specific companies if necessary (as in your original code)\n",
    "# Assuming 'filtered_list' contains economic indicators and date-based features\n",
    "filtered_list = ['Day_of_Week', 'Month', 'Quarter', 'Is_Holiday', 'Is_Month_Start', 'Is_Month_End'] + economic_indicators\n",
    "\n",
    "# Adjust DataFrames for specific companies\n",
    "special_companies = ['df_MA', 'df_MS', 'df_V', 'df_PM', 'df_GOOG']\n",
    "for comp in special_companies:\n",
    "    ticker = comp.split('_')[1]\n",
    "    all_dfs[comp] = all_dfs[comp].loc[:, all_dfs[comp].columns.str.startswith(f'{ticker}_') | all_dfs[comp].columns.isin(filtered_list)]\n",
    "    print(f\"{comp} shape after adjustment: {all_dfs[comp].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e26f0",
   "metadata": {},
   "source": [
    "## Prepare Data for Models and Serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data sequences\n",
    "def prepare_sequence_data(df, sequence_length=60, prediction_horizon=5):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Ensure the DataFrame is sorted by date\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Select relevant input features (exclude targets)\n",
    "    input_features = df.filter(regex=\"^(?!.*target).*\").values\n",
    "    targets = df.filter(regex=\"target\").values\n",
    "\n",
    "    # Create sequences\n",
    "    for i in range(len(df) - sequence_length - prediction_horizon + 1):\n",
    "        seq_x = input_features[i : i + sequence_length]\n",
    "        seq_y = targets[i + sequence_length : i + sequence_length + prediction_horizon]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y.flatten())\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data for all companies\n",
    "sequence_length = 60  # Length of input sequences\n",
    "prediction_horizon = 5  # Number of days to predict\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for company, df in all_dfs.items():\n",
    "    print(f\"Preparing data for {company}...\")\n",
    "    X_company, y_company = prepare_sequence_data(df, sequence_length, prediction_horizon)\n",
    "    X_list.append(X_company)\n",
    "    y_list.append(y_company)\n",
    "\n",
    "# Concatenate data from all companies\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "print(f\"Final shape of X: {X.shape}\")\n",
    "print(f\"Final shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data\n",
    "np.save('X_sequence_data.npy', X)\n",
    "np.save('y_sequence_data.npy', y)\n",
    "\n",
    "print(\"Preprocessed data has been saved.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
