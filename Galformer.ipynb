{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da98206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, MultiHeadAttention, LayerNormalization, Add\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e29d4",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b179631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "X = np.load('X_sequence_data.npy')\n",
    "y = np.load('y_sequence_data.npy')\n",
    "\n",
    "print(f\"Loaded X shape: {X.shape}\")\n",
    "print(f\"Loaded y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf2f7a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Data Shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing Data Shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e826c2c",
   "metadata": {},
   "source": [
    "## Add Positional Encoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012c3bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def positional_encoding(sequence_length, d_model):\n",
    "    import numpy as np\n",
    "    position = np.arange(sequence_length)[:, np.newaxis]  # shape (seq_len, 1)\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "    pe = np.zeros((sequence_length, d_model))\n",
    "    pe[:, 0::2] = np.sin(position * div_term)\n",
    "    pe[:, 1::2] = np.cos(position * div_term)\n",
    "    pe = pe[np.newaxis, ...]\n",
    "    return tf.cast(pe, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017bfc2",
   "metadata": {},
   "source": [
    "## Build and Train the Galformer Model (Transformer-based Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available GPUs\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b3fac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set memory growth for GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Galformer (Transformer) model\n",
    "def build_galformer_model(input_shape, output_length):\n",
    "    inputs = Input(shape=input_shape)  # input_shape = (sequence_length, num_features)\n",
    "    \n",
    "    # Create positional encodings\n",
    "    pe = positional_encoding(input_shape[0], input_shape[1])\n",
    "    \n",
    "    # Add positional encoding to inputs\n",
    "    x = Add()([inputs, pe])\n",
    "    \n",
    "    # Transformer Encoder Layer\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=input_shape[1])(x, x)\n",
    "    attn_output = Dropout(0.1)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(attn_output + x)\n",
    "\n",
    "    # Feed Forward Network\n",
    "    ffn_output = Dense(128, activation='relu')(out1)\n",
    "    ffn_output = Dense(input_shape[1])(ffn_output)\n",
    "    ffn_output = Dropout(0.1)(ffn_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(ffn_output + out1)\n",
    "\n",
    "    # Flatten and Output Layer\n",
    "    x = Flatten()(out2)\n",
    "    outputs = Dense(output_length, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Initialize the Galformer model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (sequence_length, num_features)\n",
    "output_length = y_train.shape[1]  # prediction_horizon\n",
    "galformer_model = build_galformer_model(input_shape, output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Galformer model\n",
    "history_galformer = galformer_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408daa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_galformer.history['loss'], label='Train Loss')\n",
    "plt.plot(history_galformer.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Galformer Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a664c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Galformer model\n",
    "test_loss_galformer, test_mae_galformer = galformer_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Galformer Model - Test Loss: {test_loss_galformer:.4f}, Test MAE: {test_mae_galformer:.4f}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_galformer = galformer_model.predict(X_test)\n",
    "\n",
    "# Visualize predictions for the first test sample\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Actual Prices for the first test sample\n",
    "plt.plot(range(1, output_length + 1), y_test[0], label=\"Actual Prices\", marker='o')\n",
    "\n",
    "# Plot Predicted Prices for the first test sample (Galformer)\n",
    "plt.plot(range(1, output_length + 1), y_pred_galformer[0], label=\"Predicted Prices (Galformer)\", marker='x')\n",
    "\n",
    "plt.title(\"Actual vs Predicted Prices (First Test Sample - Galformer)\")\n",
    "plt.xlabel(\"Days Ahead\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b0c5e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Save the Galformer model\n",
    "galformer_model.save('generalized_stock_galformer_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ac872",
   "metadata": {},
   "source": [
    "## Inference with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01e6fe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load necessary data for inference\n",
    "def load_company_data():\n",
    "    all_dfs = {}\n",
    "    parquet_files = glob.glob('df_*.parquet')\n",
    "    for file in parquet_files:\n",
    "        key = file.split('.')[0]  # e.g., 'df_AAPL'\n",
    "        df = pd.read_parquet(file)\n",
    "        all_dfs[key] = df\n",
    "    return all_dfs\n",
    "\n",
    "all_dfs = load_company_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06431266",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_inference_data(company_df, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Prepare input data for inference for a single company.\n",
    "    Args:\n",
    "        company_df (DataFrame): The DataFrame for a specific company.\n",
    "        sequence_length (int): The number of past days to consider as input.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: The input data ready for prediction.\n",
    "    \"\"\"\n",
    "    # Ensure data is sorted by date\n",
    "    company_df = company_df.sort_index()\n",
    "\n",
    "    # Select relevant input features (exclude targets)\n",
    "    input_features = company_df.filter(regex=\"^(?!.*target).*\").values\n",
    "\n",
    "    # Take the last `sequence_length` days as input for prediction\n",
    "    if len(input_features) >= sequence_length:\n",
    "        input_sequence = input_features[-sequence_length:]\n",
    "        return np.expand_dims(input_sequence, axis=0)  # Add batch dimension\n",
    "    else:\n",
    "        raise ValueError(\"Insufficient data for inference (less than sequence length).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4bb59",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_galformer_predictions_for_company(company_df, galformer_model, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Get Galformer predictions for a single company using the trained model.\n",
    "    Args:\n",
    "        company_df (DataFrame): DataFrame of the company.\n",
    "        galformer_model: Trained Galformer model.\n",
    "        sequence_length (int): Number of past days to consider as input.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Predicted prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare data for inference\n",
    "        input_data = prepare_inference_data(company_df, sequence_length=sequence_length)\n",
    "        \n",
    "        # Add positional encoding to inference data\n",
    "        pe = positional_encoding(input_shape[0], input_shape[1])\n",
    "        input_data_with_pe = input_data + pe.numpy()\n",
    "        \n",
    "        # Make predictions with Galformer\n",
    "        pred_galformer = galformer_model.predict(input_data_with_pe)\n",
    "        return pred_galformer.flatten()\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping due to error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ce1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained Galformer model\n",
    "galformer_model = load_model('generalized_stock_galformer_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299ae25",
   "metadata": {},
   "source": [
    "### Example: Making Predictions for a Specific Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658029c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Choose a company\n",
    "company_key = 'df_AAPL'  # Example company\n",
    "if company_key in all_dfs:\n",
    "    company_df = all_dfs[company_key]\n",
    "    predictions = get_galformer_predictions_for_company(company_df, galformer_model, sequence_length=60)\n",
    "    \n",
    "    if predictions is not None:\n",
    "        # Visualize predictions\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot Galformer Predictions\n",
    "        plt.plot(range(1, len(predictions) + 1), predictions, marker='x', label='Predicted Prices (Galformer)')\n",
    "        \n",
    "        plt.title(f\"Predicted Prices for {company_key} (Next {len(predictions)} Days)\")\n",
    "        plt.xlabel(\"Days Ahead\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\"No data available for {company_key}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269cb15",
   "metadata": {},
   "source": [
    "### Making Predictions for All Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add85442",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to get predictions for all companies\n",
    "def get_galformer_predictions_for_all_companies(all_dfs, galformer_model, sequence_length=60):\n",
    "    all_predictions = {}\n",
    "    for company_key, company_df in all_dfs.items():\n",
    "        predictions = get_galformer_predictions_for_company(company_df, galformer_model, sequence_length=60)\n",
    "        if predictions is not None:\n",
    "            all_predictions[company_key] = predictions\n",
    "            print(f\"Predictions for {company_key}:\")\n",
    "            print(\"Galformer Predictions:\", predictions)\n",
    "            print(\"-----------------------------\")\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c902f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Get predictions for all companies\n",
    "all_company_predictions = get_galformer_predictions_for_all_companies(all_dfs, galformer_model, sequence_length=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4acfa7",
   "metadata": {},
   "source": [
    "### Saving Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa415c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to DataFrame for further analysis or saving\n",
    "def predictions_to_dataframe(predictions_dict):\n",
    "    records = []\n",
    "    for company_key, pred_values in predictions_dict.items():\n",
    "        for day_ahead, value in enumerate(pred_values, start=1):\n",
    "            records.append({\n",
    "                'Company': company_key,\n",
    "                'Day_Ahead': day_ahead,\n",
    "                'Predicted_Price': value\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "predictions_df = predictions_to_dataframe(all_company_predictions)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c022db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions DataFrame to a CSV file\n",
    "predictions_df.to_csv('galformer_stock_price_predictions.csv', index=False)\n",
    "print(\"Galformer Predictions have been saved to 'galformer_stock_price_predictions.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
