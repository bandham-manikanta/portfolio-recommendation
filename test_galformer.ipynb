{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from fredapi import Fred\n",
    "from datetime import datetime, timedelta\n",
    "import holidays\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Fred with your API key\n",
    "fred = Fred(api_key='db61e0d65c4d2a1053221aec21822d4e')  # Replace with your actual API key securely\n",
    "\n",
    "# Define today's date\n",
    "today = pd.Timestamp.today().normalize()\n",
    "\n",
    "# Define economic indicators and their series IDs\n",
    "indicators = {\n",
    "    'Effective Federal Funds Rate': 'FEDFUNDS',\n",
    "    '10-Year Treasury Rate': 'DGS10',\n",
    "    'Consumer Price Index': 'CPIAUCSL',\n",
    "    'Producer Price Index': 'PPIACO',\n",
    "    'Unemployment Rate': 'UNRATE',\n",
    "    'Nonfarm Payroll Employment': 'PAYEMS',\n",
    "    'Real GDP': 'GDPC1',\n",
    "    'Housing Starts': 'HOUST',\n",
    "    'Industrial Production Index': 'INDPRO',\n",
    "    'M2 Money Stock': 'M2SL',\n",
    "    'Crude Oil Prices': 'DCOILWTICO',\n",
    "    'Retail Sales': 'RSXFS',\n",
    "    'Total Business Inventories': 'BUSINV'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_economic_data_for_today(indicators):\n",
    "    economic_data = pd.DataFrame()\n",
    "    for name, series_id in indicators.items():\n",
    "        try:\n",
    "            # Fetch the latest data point\n",
    "            data = fred.get_series_latest_release(series_id)\n",
    "            if data is not None and not data.empty:\n",
    "                latest_value = data.iloc[-1]\n",
    "                latest_date = data.index[-1]\n",
    "                # Use the latest available value for today\n",
    "                economic_data.at[today, name] = latest_value\n",
    "                print(f\"Successfully fetched data for {name}: {latest_value} on {latest_date.date()}\")\n",
    "            else:\n",
    "                print(f\"No data fetched for {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {name}: {e}\")\n",
    "    economic_data.index = pd.to_datetime(economic_data.index)\n",
    "    return economic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker):\n",
    "    # Fetch stock data for the ticker up to today\n",
    "    # We'll get enough historical data to compute the technical indicators\n",
    "    start_date = today - timedelta(days=365)  # Assuming we need one year of data\n",
    "    # Adding one day to end date to include today's data\n",
    "    stock_data = yf.download(\n",
    "        ticker,\n",
    "        start=start_date.strftime('%Y-%m-%d'),\n",
    "        end=(today + timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "        progress=False,\n",
    "        group_by='ticker'\n",
    "    )\n",
    "    if stock_data.empty:\n",
    "        print(f\"No stock data fetched for {ticker} between {start_date.date()} and {today.date()}\")\n",
    "        return None\n",
    "\n",
    "    stock_data.index = pd.to_datetime(stock_data.index)\n",
    "\n",
    "    # Flatten columns if MultiIndex\n",
    "    if isinstance(stock_data.columns, pd.MultiIndex):\n",
    "        stock_data.columns = stock_data.columns.get_level_values(1)\n",
    "\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Calculate Technical Indicators\n",
    "\n",
    "# %%\n",
    "def calculate_technical_indicators(data, ticker):\n",
    "    close_col = 'Close'\n",
    "    if close_col in data.columns:\n",
    "        # Calculate technical indicators\n",
    "        data[f'{ticker}_SMA_20'] = ta.sma(data[close_col], length=20)\n",
    "        data[f'{ticker}_RSI_14'] = ta.rsi(data[close_col], length=14)\n",
    "        macd = ta.macd(data[close_col], fast=12, slow=26)\n",
    "        if macd is not None and not macd.empty:\n",
    "            macd_columns = [f'{ticker}_MACD', f'{ticker}_MACD_Hist', f'{ticker}_MACD_Signal']\n",
    "            macd.columns = macd_columns\n",
    "            data = pd.concat([data, macd], axis=1)\n",
    "        else:\n",
    "            print(f\"Failed to calculate MACD for {ticker}\")\n",
    "        bbands = ta.bbands(data[close_col], length=20)\n",
    "        if bbands is not None and not bbands.empty:\n",
    "            bbands_columns = [\n",
    "                f'{ticker}_BB_Lower', f'{ticker}_BB_Middle', f'{ticker}_BB_Upper',\n",
    "                f'{ticker}_BB_Bandwidth', f'{ticker}_BB_Percentage'\n",
    "            ]\n",
    "            bbands.columns = bbands_columns\n",
    "            data = pd.concat([data, bbands], axis=1)\n",
    "        else:\n",
    "            print(f\"Failed to calculate Bollinger Bands for {ticker}\")\n",
    "        data[f'{ticker}_MOM_10'] = ta.mom(data[close_col], length=10)\n",
    "    else:\n",
    "        print(f\"Missing 'Close' column in stock data for {ticker}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Prepare Input Features\n",
    "\n",
    "# %%\n",
    "def prepare_input_features(stock_data, economic_data, ticker):\n",
    "    # Ensure indices are single-level and have the same name\n",
    "    if stock_data.index.nlevels > 1:\n",
    "        stock_data.reset_index(inplace=True)\n",
    "        stock_data.set_index('Date', inplace=True)\n",
    "    if economic_data.index.nlevels > 1:\n",
    "        economic_data.reset_index(inplace=True)\n",
    "        economic_data.set_index('Date', inplace=True)\n",
    "\n",
    "    stock_data.index.name = 'Date'\n",
    "    economic_data.index.name = 'Date'\n",
    "\n",
    "    # Ensure indices are DatetimeIndex\n",
    "    stock_data.index = pd.to_datetime(stock_data.index)\n",
    "    economic_data.index = pd.to_datetime(economic_data.index)\n",
    "\n",
    "    # Merge stock data and economic data\n",
    "    combined_data = pd.merge(stock_data, economic_data, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # Fill missing values\n",
    "    combined_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Calculate technical indicators\n",
    "    combined_data = calculate_technical_indicators(combined_data, ticker)\n",
    "\n",
    "    # Create lag features\n",
    "    n_lags = 5\n",
    "    lagged_features = {}\n",
    "    close_col = 'Close'\n",
    "    if close_col in combined_data.columns:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            lag_col_name = f'{ticker}_Close_Lag_{lag}'\n",
    "            lagged_features[lag_col_name] = combined_data[close_col].shift(lag)\n",
    "    else:\n",
    "        print(f\"Column {close_col} not found in stock data.\")\n",
    "    # Create lag features for economic indicators\n",
    "    for indicator in indicators.keys():\n",
    "        if indicator in combined_data.columns:\n",
    "            for lag in range(1, n_lags + 1):\n",
    "                lag_col_name = f'{indicator}_Lag_{lag}'\n",
    "                lagged_features[lag_col_name] = combined_data[indicator].shift(lag)\n",
    "        else:\n",
    "            print(f\"Indicator {indicator} not found in combined_data.\")\n",
    "    # Convert the lagged features dictionary to a DataFrame\n",
    "    lagged_features_df = pd.DataFrame(lagged_features, index=combined_data.index)\n",
    "    # Concatenate the lagged features DataFrame to the original DataFrame\n",
    "    combined_data = pd.concat([combined_data, lagged_features_df], axis=1)\n",
    "\n",
    "    # Extract Date-Based Features\n",
    "    combined_data['Day_of_Week'] = combined_data.index.dayofweek  # Monday=0, Sunday=6\n",
    "    combined_data['Month'] = combined_data.index.month\n",
    "    combined_data['Quarter'] = combined_data.index.quarter\n",
    "    us_holidays = holidays.US()\n",
    "    combined_data['Is_Holiday'] = combined_data.index.isin(us_holidays).astype(int)\n",
    "    combined_data['Is_Month_Start'] = combined_data.index.is_month_start.astype(int)\n",
    "    combined_data['Is_Month_End'] = combined_data.index.is_month_end.astype(int)\n",
    "\n",
    "    # **Load the feature names used during training**\n",
    "    try:\n",
    "        with open('combined_data_columns.txt', 'r') as f:\n",
    "            trained_features = [line.strip() for line in f.readlines()]\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file 'combined_data_columns.txt' was not found. Ensure it exists and contains the feature names used during training.\")\n",
    "        return None\n",
    "\n",
    "    # **Ensure these features are present in combined_data**\n",
    "    missing_features = [feat for feat in trained_features if feat not in combined_data.columns]\n",
    "    if missing_features:\n",
    "        print(f\"The following trained features are missing in the inference data: {missing_features}\")\n",
    "        return None\n",
    "\n",
    "    # **Filter combined_data to include only the trained features**\n",
    "    combined_data = combined_data[trained_features]\n",
    "\n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Positional Encoding Functions\n",
    "\n",
    "# %%\n",
    "def positional_encoding(sequence_length, d_model):\n",
    "    position = np.arange(sequence_length)[:, np.newaxis]\n",
    "    i = np.arange(d_model)[np.newaxis, :]\n",
    "    angle_rates = 1 / np.power(10000.0, (2 * (i//2)) / np.float32(d_model))\n",
    "    angle_rads = position * angle_rates\n",
    "    sin_terms = np.sin(angle_rads[:, 0::2])\n",
    "    cos_terms = np.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = np.zeros((sequence_length, d_model))\n",
    "    pos_encoding[:, 0::2] = sin_terms\n",
    "    pos_encoding[:, 1::2] = cos_terms\n",
    "    return pos_encoding\n",
    "\n",
    "def add_positional_encoding(inputs):\n",
    "    pe = positional_encoding(inputs.shape[1], inputs.shape[2])\n",
    "    pe = np.expand_dims(pe, axis=0)  # Shape: (1, sequence_length, num_features)\n",
    "    inputs_with_pe = inputs + pe\n",
    "    return inputs_with_pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched data for Effective Federal Funds Rate: 4.64 on 2024-11-01\n",
      "Successfully fetched data for 10-Year Treasury Rate: 4.18 on 2024-11-29\n",
      "Successfully fetched data for Consumer Price Index: 315.454 on 2024-10-01\n",
      "Successfully fetched data for Producer Price Index: 253.452 on 2024-10-01\n",
      "Successfully fetched data for Unemployment Rate: 4.1 on 2024-10-01\n",
      "Successfully fetched data for Nonfarm Payroll Employment: 159005.0 on 2024-10-01\n",
      "Successfully fetched data for Real GDP: 23386.733 on 2024-07-01\n",
      "Successfully fetched data for Housing Starts: 1311.0 on 2024-10-01\n",
      "Successfully fetched data for Industrial Production Index: 102.2805 on 2024-10-01\n",
      "Successfully fetched data for M2 Money Stock: 21311.2 on 2024-10-01\n",
      "Successfully fetched data for Crude Oil Prices: 69.41 on 2024-11-25\n",
      "Successfully fetched data for Retail Sales: 621590.0 on 2024-10-01\n",
      "Successfully fetched data for Total Business Inventories: 2587145.0 on 2024-09-01\n",
      "Using data from 2024-12-02 instead of today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbandham\\AppData\\Local\\Temp\\ipykernel_8156\\221654949.py:82: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  today_data_filled = today_data[required_columns].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Main Code to Prepare Input Sequence and Make Prediction\n",
    "\n",
    "# %%\n",
    "def main():\n",
    "    ticker = 'AAPL'\n",
    "    today = pd.Timestamp.today().normalize()\n",
    "    \n",
    "    # Fetch economic data\n",
    "    economic_data = fetch_economic_data_for_today(indicators)\n",
    "    if economic_data.empty:\n",
    "        print(\"Economic data is empty.\")\n",
    "        return\n",
    "\n",
    "    # Fetch stock data\n",
    "    stock_data = fetch_stock_data(ticker)\n",
    "    if stock_data is None:\n",
    "        print(\"Stock data is empty.\")\n",
    "        return\n",
    "\n",
    "    # Prepare input features\n",
    "    combined_data = prepare_input_features(stock_data, economic_data, ticker)\n",
    "    if combined_data is None:\n",
    "        print(\"Failed to prepare input features.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the DataFrame is sorted by date\n",
    "    combined_data.sort_index(inplace=True)\n",
    "\n",
    "    # Prepare input sequence\n",
    "    sequence_length = 60  # Should match the sequence length used during training\n",
    "    if len(combined_data) >= sequence_length:\n",
    "        input_sequence = combined_data.tail(sequence_length).values  # Shape: (sequence_length, num_features)\n",
    "        # Check for NaNs\n",
    "        if np.isnan(input_sequence).any():\n",
    "            print(\"Input sequence contains NaN values after feature calculation.\")\n",
    "            return\n",
    "        # Normalize features (per sample as during training)\n",
    "        feature_mean = np.mean(input_sequence, axis=0, keepdims=True)\n",
    "        feature_std = np.std(input_sequence, axis=0, keepdims=True) + 1e-6\n",
    "        normalized_input_sequence = (input_sequence - feature_mean) / feature_std\n",
    "        # Reshape to (1, sequence_length, num_features)\n",
    "        normalized_input_sequence = normalized_input_sequence.reshape(1, sequence_length, -1).astype(np.float32)\n",
    "    else:\n",
    "        print(f\"Not enough data to form input sequence of length {sequence_length}\")\n",
    "        return\n",
    "\n",
    "    # Add positional encoding\n",
    "    inputs_with_pe = add_positional_encoding(normalized_input_sequence)\n",
    "\n",
    "    # Load the trained model\n",
    "    try:\n",
    "        model = tf.keras.models.load_model('enhanced_stock_galformer_model.keras')\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(inputs_with_pe)\n",
    "    print(f\"Predictions (standardized) shape: {predictions.shape}\")\n",
    "\n",
    "    # Since labels were normalized during training per sample, and during inference we don't have label mean and std,\n",
    "    # these predictions are in standardized form and cannot be directly denormalized.\n",
    "    # If you have global label_mean and label_std from training data, use them here to denormalize.\n",
    "    # For now, we will print the standardized predictions.\n",
    "\n",
    "    print(\"Predictions (standardized):\")\n",
    "    print(predictions.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'data': feature_row})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ams_560_bdata_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
